{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision.transforms import Lambda\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_hidden, num_users, dropout=0.05,mode = 'train'):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_users,num_hidden),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Linear(num_hidden,num_users)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mode = mode\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.dropout(self.encoder(X)) #(b,num_users) ->(b,num_hidden)\n",
    "        y = self.decoder(hidden) #(b,num_hidden) ->(b,num_users)\n",
    "        if self.mode=='train':  # Mask the gradient during training\n",
    "            return y * torch.sign(X) # -1 if x < 0, 0 if x==0, 1 if x > 0. X中未标注的数据为0，用来屏蔽未标注的输入的梯度对模型的影响\n",
    "        else:\n",
    "            return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, mat,transform=None):\n",
    "        self.mat = mat\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.mat.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.mat[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12548\\AppData\\Local\\Temp/ipykernel_24884/700341194.py:47: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  data, num_users, num_items = read_data_ml100k()\n"
     ]
    }
   ],
   "source": [
    "def read_data_ml100k():\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv('../../data/ml-100k/u.data', '\\t', names=names,engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items\n",
    "\n",
    "def split_data_ml100k(data, num_users, split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time)) # 如果键不在字典里，setdefault将键和默认值添加到字典中，最后返回该键对应的值。这里返回list，通过append将所有相同user的item放到同一个key对应的value里。\n",
    "            if u not in test_items or test_items[u][-1] < time: # 将最新的item放到test_items\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3])) # 将每个user对应的value 按照时间戳从小到大排序放到train_list\n",
    "        test_data = [(key, *value) for key, value in test_items.items()] # 将test_items变成list\n",
    "        train_data = [item for item in train_list if item not in test_data] #将train_list不在test_data里的元素放到train_data\n",
    "        train_data = pd.DataFrame(train_data)\n",
    "        test_data = pd.DataFrame(test_data)\n",
    "    else:\n",
    "        mask = np.random.uniform(0, 1, (len(data))) < 1 - test_ratio # 生成(len(data),)大小的bool类型数组 随机test_ratio比例的元素为False，其余为True\n",
    "        neg_mask = [not x for x in mask] # 生成len(data)长度的bool类型list 元素和mask相反\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1) #0~942 0~1681\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index) # 隐式则为字典 key为user，value为按时间排序的item list\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter\n",
    "\n",
    "\n",
    "def split_and_load_ml100k(split_mode='random', feedback='explicit',\n",
    "                          test_ratio=0.1, batch_size=256):\n",
    "    data, num_users, num_items = read_data_ml100k()\n",
    "    train_data, test_data = split_data_ml100k(\n",
    "        data, num_users, split_mode, test_ratio)\n",
    "    _, _, _, train_inter_mat = load_data_ml100k(train_data, num_users, num_items, feedback)\n",
    "    _, _, _, test_inter_mat = load_data_ml100k(test_data, num_users, num_items, feedback)\n",
    "    transform = Lambda(lambda x: torch.tensor(x,dtype=torch.float))\n",
    "    train_set = InteractionDataset(train_inter_mat,transform)\n",
    "    test_set = InteractionDataset(test_inter_mat,transform)\n",
    "    train_iter = DataLoader(train_set, shuffle=True, batch_size=batch_size)\n",
    "    test_iter = DataLoader(test_set, batch_size=batch_size)\n",
    "    return num_users, num_items, train_iter, test_iter\n",
    "\n",
    "num_users, num_items, train_iter, test_iter = split_and_load_ml100k()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def evaluate_loss(data_iter, net,loss, device=None):\n",
    "    \"\"\"\n",
    "    输出y为某个值时\n",
    "    :param data_iter:\n",
    "    :param net:\n",
    "    :param device:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for x in data_iter:\n",
    "            net.eval() # 评估模式, 这会关闭dropout\n",
    "            x = x.to(device)\n",
    "            y_hat = net(x)\n",
    "            l = loss(y_hat, x).cpu().item()\n",
    "            net.train() # 改回训练模式\n",
    "    return l\n",
    "def train(net, train_iter, test_iter, optimizer,loss, device, num_epochs,oneHotEncoder=None,scheduler = None):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    plt_epoch = []\n",
    "    plt_train_loss = []\n",
    "    plt_test_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        plt_epoch.append(epoch)\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for x in tqdm(train_iter):\n",
    "            x = x.to(device)\n",
    "            y_hat = net(x)\n",
    "            l = loss(y_hat, x)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            # grad_clipping(net, 1)\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            n += x.shape[0] # batch_num\n",
    "            batch_count += 1\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        test_loss = evaluate_loss(test_iter, net,loss,device)\n",
    "        plt_test_loss.append(test_loss)\n",
    "        plt_train_loss.append(train_l_sum / batch_count)\n",
    "        print('epoch %d, train_loss %.4f,train_loss %.4f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count,test_loss, time.time() - start))\n",
    "    plt.plot(plt_epoch, plt_train_loss, color='r', label='train')  # r表示红色\n",
    "    plt.plot(plt_epoch, plt_test_loss, color='b', label='test')  \n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, train_loss 0.4661,train_loss 0.0146, time 0.3 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 125.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, train_loss 0.2868,train_loss 0.0145, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 125.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, train_loss 0.2655,train_loss 0.0130, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 127.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, train_loss 0.2611,train_loss 0.0128, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 120.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, train_loss 0.2556,train_loss 0.0122, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 127.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, train_loss 0.2526,train_loss 0.0121, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 122.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, train_loss 0.2490,train_loss 0.0119, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 120.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, train_loss 0.2434,train_loss 0.0121, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 119.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, train_loss 0.2370,train_loss 0.0118, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 116.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, train_loss 0.2307,train_loss 0.0123, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 118.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, train_loss 0.2272,train_loss 0.0124, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 99.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, train_loss 0.2244,train_loss 0.0126, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 127.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, train_loss 0.2226,train_loss 0.0131, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 125.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, train_loss 0.2211,train_loss 0.0127, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 129.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, train_loss 0.2206,train_loss 0.0135, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 116.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, train_loss 0.2193,train_loss 0.0135, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [00:00<00:00, 131.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, train_loss 0.2197,train_loss 0.0135, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 127.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, train_loss 0.2201,train_loss 0.0131, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 118.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, train_loss 0.2173,train_loss 0.0131, time 0.1 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 119.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, train_loss 0.2168,train_loss 0.0127, time 0.1 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "'\\n测试1：\\nepoch 1, train_loss 0.5147,train_loss 0.0131, time 1.8 sec\\nepoch 2, train_loss 0.3148,train_loss 0.0169, time 0.1 sec\\nepoch 20, train_loss 0.1679,train_loss 0.0110, time 0.1 sec\\n参数：num_hidden=500\\n结构：\\nself.encoder = nn.Sequential(\\n            nn.Linear(num_users,num_hidden),\\n            nn.Sigmoid()\\n        )\\n        self.decoder = nn.Linear(num_hidden,num_users)\\n        self.dropout = nn.Dropout(dropout)\\n        self.mode = mode\\n\\n测试2：\\nepoch 1, train_loss 0.4730,train_loss 0.0178, time 2.2 sec\\nepoch 2, train_loss 0.2741,train_loss 0.0165, time 0.1 sec\\nepoch 20, train_loss 0.1423,train_loss 0.0144, time 0.1 sec\\n参数：num_hidden=1000\\n结构：\\n同测试1\\n\\n测试3：\\nepoch 1, train_loss 0.6960,train_loss 0.0304, time 0.1 sec\\nepoch 2, train_loss 0.3120,train_loss 0.0203, time 0.1 sec\\nepoch 20, train_loss 0.2035,train_loss 0.0181, time 0.1 sec\\n参数：num_hidden=200\\n结构：\\n同测试1\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RMSELoss(yhat,y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
    "loss = RMSELoss\n",
    "net = AutoRec(500,num_users)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.002)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 20\n",
    "train(net,train_iter,test_iter,optimizer,loss,device,num_epoch)\n",
    "\"\"\"\n",
    "测试1：\n",
    "epoch 1, train_loss 0.5147,train_loss 0.0131, time 1.8 sec\n",
    "epoch 2, train_loss 0.3148,train_loss 0.0169, time 0.1 sec\n",
    "epoch 20, train_loss 0.1679,train_loss 0.0110, time 0.1 sec\n",
    "参数：num_hidden=500\n",
    "结构：\n",
    "self.encoder = nn.Sequential(\n",
    "            nn.Linear(num_users,num_hidden),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Linear(num_hidden,num_users)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mode = mode\n",
    "\n",
    "测试2：\n",
    "epoch 1, train_loss 0.4730,train_loss 0.0178, time 2.2 sec\n",
    "epoch 2, train_loss 0.2741,train_loss 0.0165, time 0.1 sec\n",
    "epoch 20, train_loss 0.1423,train_loss 0.0144, time 0.1 sec\n",
    "参数：num_hidden=1000\n",
    "结构：\n",
    "同测试1\n",
    "\n",
    "测试3：\n",
    "epoch 1, train_loss 0.6960,train_loss 0.0304, time 0.1 sec\n",
    "epoch 2, train_loss 0.3120,train_loss 0.0203, time 0.1 sec\n",
    "epoch 20, train_loss 0.2035,train_loss 0.0181, time 0.1 sec\n",
    "参数：num_hidden=200\n",
    "结构：\n",
    "同测试1\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-ff83aeb4",
   "language": "python",
   "display_name": "PyCharm (MLWorkspace)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}