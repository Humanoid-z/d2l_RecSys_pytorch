{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_factors, num_users, num_items, nums_hiddens):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.P = nn.Embedding(num_users, num_factors)\n",
    "        self.Q = nn.Embedding(num_items, num_factors)\n",
    "        self.U = nn.Embedding(num_users, num_factors)\n",
    "        self.V = nn.Embedding(num_items, num_factors)\n",
    "        self.mlp = nn.Sequential()\n",
    "        pre_num_hiddens = num_factors*2\n",
    "        for i in range(0,len(nums_hiddens)):\n",
    "            self.mlp.add_module('mlp'+str(i),\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(pre_num_hiddens,nums_hiddens[i]),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            )\n",
    "            pre_num_hiddens = nums_hiddens[i]\n",
    "        self.prediction_layer = nn.Sequential(\n",
    "            nn.Linear(pre_num_hiddens+num_factors,1,bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        p_mf = self.P(user_id)\n",
    "        q_mf = self.Q(item_id)\n",
    "        gmf = p_mf * q_mf\n",
    "        p_mlp = self.U(user_id) # (b,1)->(b,num_factors)\n",
    "        q_mlp = self.V(item_id) # (b,1)->(b,num_factors)\n",
    "        mlp = self.mlp(torch.concat([p_mlp, q_mlp], dim=1)) # (b,num_factors*2)->(b,last_num_hiddens)\n",
    "        con_res = torch.concat([gmf, mlp], dim=1) # (b,last_num_hiddens+num_factors)\n",
    "        return self.prediction_layer(con_res) # (b,last_num_hiddens+num_factors)->(b,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class PRDataset(Dataset):\n",
    "    def __init__(self, users, inter, num_items):\n",
    "        \"\"\"\n",
    "\n",
    "        :param users:\n",
    "        :param items:\n",
    "        :param inter: 字典 key为user，value为按时间排序的评价过的item\n",
    "        :param num_items:\n",
    "        \"\"\"\n",
    "        self.users = users\n",
    "        self.inter = inter\n",
    "        self.all = set([i for i in range(num_items)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        neg_items = list(self.all - set(self.inter[int(self.users[idx])]))\n",
    "        pos_items = self.inter[int(self.users[idx])]\n",
    "        neg_indices = random.randint(0, len(neg_items) - 1)\n",
    "        pos_indices = random.randint(0, len(pos_items) - 1)\n",
    "        return self.users[idx], pos_items[pos_indices], neg_items[neg_indices]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ArrayDataset(Dataset):\n",
    "    def __init__(self, ArrayData,transform=None):\n",
    "        self._data  = ArrayData\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return tuple(data[idx] for data in self._data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def hit_and_auc(rankedlist, test_matrix, k):\n",
    "    \"\"\"\n",
    "    计算每个用户的命中数和 AUC。\n",
    "    :param rankedlist:\n",
    "    :param test_matrix: 用户真正交互的item\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    hits_k = [(idx, val) for idx, val in enumerate(rankedlist[:k])\n",
    "              if val in set(test_matrix)]\n",
    "    hits_all = [(idx, val) for idx, val in enumerate(rankedlist)\n",
    "                if val in set(test_matrix)]\n",
    "    max = len(rankedlist) - 1\n",
    "    auc = 1.0 * (max - hits_all[0][0]) / max if len(hits_all) > 0 else 0\n",
    "    return len(hits_k), auc\n",
    "\n",
    "#@save\n",
    "def evaluate_ranking(net, test_input, candidates,num_users, num_items,device):\n",
    "    ranked_list, ranked_items, hit_rate, auc = {}, {}, [], []\n",
    "    all_items = set([i for i in range(num_items)])\n",
    "    for u in tqdm(range(num_users)):\n",
    "        neg_items = list(all_items - set(candidates[int(u)]))\n",
    "        user_ids, item_ids, x, scores = [], [], [], []\n",
    "        [item_ids.append(i) for i in neg_items] #记录u没有评价的item id\n",
    "        [user_ids.append(u) for _ in neg_items] #u的id，和item_ids长度相同\n",
    "        x.extend([np.array(user_ids)])\n",
    "        x.extend([np.array(item_ids)])\n",
    "        # x[0]:len=len(neg_items) 元素全为u,x[1]:len=len(neg_items) 元素为neg_items的id\n",
    "        x = np.array(x)\n",
    "        x = torch.tensor(x)\n",
    "        test_data_set = ArrayDataset(x)\n",
    "        test_data_iter = DataLoader(test_data_set, shuffle=False, batch_size=1024)\n",
    "        for user_id, item_id in test_data_iter:\n",
    "            user_id = user_id.to(device)\n",
    "            item_id = item_id.to(device)\n",
    "            score = net(user_id,item_id)\n",
    "            scores.extend(score)\n",
    "        scores = [item for sublist in scores for item in sublist]\n",
    "        item_scores = list(zip(item_ids, scores))\n",
    "        ranked_list[u] = sorted(item_scores, key=lambda t: t[1], reverse=True)\n",
    "        ranked_items[u] = [r[0] for r in ranked_list[u]]\n",
    "        true_item = int(test_input[test_input.u==u+1].i)-1\n",
    "        temp = hit_and_auc(ranked_items[u], [true_item], 50)\n",
    "        hit_rate.append(temp[0])\n",
    "        auc.append(temp[1])\n",
    "    return np.mean(np.array(hit_rate)), np.mean(np.array(auc))\n",
    "\n",
    "#@save\n",
    "def train_ranking(net, train_iter, test_input, optimizer,loss,num_users,num_items, num_epochs, device, evaluator,candidates):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    plt_epoch = []\n",
    "    for epoch in range(num_epochs):\n",
    "        plt_epoch.append(epoch)\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for u, pos_item,neg_item in tqdm(train_iter):\n",
    "            u = u.to(device)\n",
    "            pos_item = pos_item.to(device)\n",
    "            neg_item = neg_item.to(device)\n",
    "\n",
    "            p_pos = net(u,pos_item)\n",
    "            p_neg = net(u,neg_item)\n",
    "            l = loss(p_pos, p_neg)\n",
    "            train_l_sum += l.sum().cpu().item()\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            batch_count+=1\n",
    "        with torch.no_grad():\n",
    "            hit_rate, auc = evaluator(net, test_input,candidates,num_users, num_items,device)\n",
    "        print('epoch %d,train_loss %.4f,hit_rate %.4f,auc %.4f, time %.1f sec'\n",
    "              % (epoch + 1,train_l_sum / batch_count,hit_rate,auc, time.time() - start))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def read_data_ml100k():\n",
    "    names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv('../../data/ml-100k/u.data', '\\t', names=names,engine='python')\n",
    "    num_users = data.user_id.unique().shape[0]\n",
    "    num_items = data.item_id.unique().shape[0]\n",
    "    return data, num_users, num_items\n",
    "\n",
    "def split_data_ml100k(data, num_users, split_mode='random', test_ratio=0.1):\n",
    "    \"\"\"Split the dataset in random mode or seq-aware mode.\"\"\"\n",
    "    if split_mode == 'seq-aware':\n",
    "        train_items, test_items, train_list = {}, {}, []\n",
    "        for line in data.itertuples():\n",
    "            u, i, rating, time = line[1], line[2], line[3], line[4]\n",
    "            train_items.setdefault(u, []).append((u, i, rating, time)) # 如果键不在字典里，setdefault将键和默认值添加到字典中，最后返回该键对应的值。这里返回list，通过append将所有相同user的item放到同一个key对应的value里。\n",
    "            if u not in test_items or test_items[u][-1] < time: # 将最新的item放到test_items\n",
    "                test_items[u] = (i, rating, time)\n",
    "        for u in range(1, num_users + 1):\n",
    "            train_list.extend(sorted(train_items[u], key=lambda k: k[3])) # 将每个user对应的value 按照时间戳从小到大排序放到train_list\n",
    "        test_data = [(key, *value) for key, value in test_items.items()] # 将test_items变成list\n",
    "        train_data = [item for item in train_list if item not in test_data] #将train_list不在test_data里的元素放到train_data\n",
    "        train_data = pd.DataFrame(train_data,columns=['u', 'i', 'rating', 'time'])\n",
    "        test_data = pd.DataFrame(test_data,columns=['u', 'i', 'rating', 'time'])\n",
    "    else:\n",
    "        mask = np.random.uniform(0, 1, (len(data))) < (1 - test_ratio)# 生成(len(data),)大小的bool类型数组 随机test_ratio比例的元素为False，其余为True\n",
    "        neg_mask = [not x for x in mask] # 生成len(data)长度的bool类型list 元素和mask相反\n",
    "        train_data, test_data = data[mask], data[neg_mask]\n",
    "    return train_data, test_data\n",
    "\n",
    "def load_data_ml100k(data, num_users, num_items, feedback='explicit'):\n",
    "    users, items, scores = [], [], []\n",
    "    inter = np.zeros((num_items, num_users)) if feedback == 'explicit' else {}\n",
    "    for line in data.itertuples():\n",
    "        user_index, item_index = int(line[1] - 1), int(line[2] - 1) #0~942 0~1681\n",
    "        score = int(line[3]) if feedback == 'explicit' else 1\n",
    "        users.append(user_index)\n",
    "        items.append(item_index)\n",
    "        scores.append(score)\n",
    "        if feedback == 'implicit':\n",
    "            inter.setdefault(user_index, []).append(item_index) # 隐式则为字典 key为user，value为按时间排序的item list\n",
    "        else:\n",
    "            inter[item_index, user_index] = score\n",
    "    return users, items, scores, inter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12548\\AppData\\Local\\Temp/ipykernel_21904/2111376494.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only\n",
      "  df, num_users, num_items = read_data_ml100k()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n",
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:09<00:00, 84.27it/s] \n",
      "100%|██████████| 943/943 [22:22<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,train_loss 69.4006,hit_rate 0.0976,auc 0.7205, time 1351.8 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:07<00:00, 101.01it/s]\n",
      "100%|██████████| 943/943 [22:02<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2,train_loss 66.5728,hit_rate 0.1273,auc 0.7186, time 1330.5 sec\n"
     ]
    }
   ],
   "source": [
    "df, num_users, num_items = read_data_ml100k()\n",
    "print(num_users,num_items)\n",
    "train_data, test_data = split_data_ml100k(df, num_users,'seq-aware')\n",
    "users_train, items_train, ratings_train, candidates = load_data_ml100k(train_data, num_users, num_items, feedback=\"implicit\")\n",
    "# 因为使用train_data ，candidates 不包括user最新交互的item\n",
    "def BPRLoss(positive,negative):\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    return - torch.sum(torch.log(sigmoid(positive - negative)), dim=0, keepdim=True)\n",
    "net = NeuMF(10,num_users, num_items, nums_hiddens=[10, 10, 10])\n",
    "loss = BPRLoss\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_epoch = 2\n",
    "train_set = PRDataset(users_train, candidates, num_items)\n",
    "train_iter = DataLoader(train_set,batch_size=128,shuffle=True)\n",
    "evaluator = evaluate_ranking\n",
    "train_ranking(net, train_iter, test_data, optimizer,loss,num_users,num_items, num_epoch, device, evaluator,candidates)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}